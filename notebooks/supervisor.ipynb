{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervisor Agent Testing \n",
    "\n",
    "Can we build an agent that can:\n",
    "- Determine what transformation pipeline a given input should go to\n",
    "- Schedule + run that job for us?\n",
    "\n",
    "While this usecase isn't particularly compelling given we have 2 sources of reliably structured data, the broader applications are interesting. Think about the case of unstructured data. It would be unreasonable to write special conditions for every edge case you come across, however, an LLM could assist in making a reasonable guess as to which transformation pipline might be the best fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import subprocess\n",
    "\n",
    "# get root of current repo and add to our path\n",
    "root_dir = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], stderr=subprocess.DEVNULL).decode(\"utf-8\").strip()\n",
    "\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Supervisor Agent\n",
    "\n",
    "Now that we have an S3 Tool to grab raw data + extract metadata and an Airflow Tool that can help us trigger DAGs via TaskFlow API, we're ready to build our agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from airflow.dags.utils.airflow_client import AirflowClient\n",
    "\n",
    "# define the set of available tools for our agent\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"TriggerAirflowDAG\", \n",
    "        func=lambda dag_id: AirflowClient.trigger_dag(dag_id=dag_id),\n",
    "        description=\"Trigger an Airflow DAG. The DAG is specified by its ID.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the language model for our agent\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# initialize the agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools, \n",
    "    llm=llm, \n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.dags.utils.aws import S3 \n",
    "import os \n",
    "\n",
    "def run_supervisor_agent(date):\n",
    "\n",
    "    # get a list of s3 keys for a specific dates scrape \n",
    "    s3_keys = S3.get_keys_by_date(date=date, role_arn=os.getenv(\"DIGI_INNO_ROLE_ARN\"))\n",
    "\n",
    "    # get file meta \n",
    "    metadata = S3.get_file_metadata(key=s3_keys[0], chars_to_sample=500, role_arn=os.getenv(\"DIGI_INNO_ROLE_ARN\"))\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        You are a supervisor agent. Your task is to examine the file content and decide which Airflow DAG should be triggered.\n",
    "\n",
    "        Here is the metadata:\n",
    "        {metadata}\n",
    "\n",
    "        Choose the correct DAG ID from:\n",
    "        - transform_pbs_data\n",
    "        - transform_npr_data\n",
    "\n",
    "        Then call TriggerAirflowDAG with the correct DAG ID.\n",
    "    \"\"\"\n",
    "\n",
    "    print(agent.run(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "[\u001b[34m2025-06-11T14:50:20.621-0400\u001b[0m] {\u001b[34m_client.py:\u001b[0m1026} INFO\u001b[0m - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe file content seems to be an XML file from NPR (National Public Radio) as indicated by the URL and the XML namespaces. Therefore, the appropriate DAG to trigger would be the one related to NPR data.\n",
      "\n",
      "Action: TriggerAirflowDAG\n",
      "Action Input: transform_npr_data\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'status_code': 200, 'response': {'dag_run_id': 'manual__2025-06-11T18:50:20.627438+00:00', 'dag_id': 'transform_npr_data', 'logical_date': '2025-06-11T18:50:20.627438Z', 'queued_at': '2025-06-11T18:50:20.879650Z', 'start_date': None, 'end_date': None, 'data_interval_start': '2025-06-11T18:50:20.627438Z', 'data_interval_end': '2025-06-11T18:50:20.627438Z', 'run_after': '2025-06-11T18:50:20.627438Z', 'last_scheduling_decision': None, 'run_type': 'manual', 'state': 'queued', 'triggered_by': 'rest_api', 'conf': {}, 'note': None, 'dag_versions': [{'id': '01971349-3582-7e92-82ab-3870aa206c32', 'version_number': 1, 'dag_id': 'transform_npr_data', 'bundle_name': 'dags-folder', 'bundle_version': None, 'created_at': '2025-05-27T19:47:34.402720Z', 'bundle_url': None}], 'bundle_version': None}}\u001b[0m\n",
      "Thought:[\u001b[34m2025-06-11T14:50:25.577-0400\u001b[0m] {\u001b[34m_client.py:\u001b[0m1026} INFO\u001b[0m - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe DAG 'transform_npr_data' has been successfully triggered as indicated by the status code 200 in the observation. The DAG is currently in the 'queued' state and will run after the specified 'run_after' time.\n",
      "Final Answer: The 'transform_npr_data' DAG has been successfully triggered for the file 'bronze/05222025/https%3A%2F%2Fwww.npr.org%2Frss%2Frss.php%3Fid%3D10001_05222025.xml'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The 'transform_npr_data' DAG has been successfully triggered for the file 'bronze/05222025/https%3A%2F%2Fwww.npr.org%2Frss%2Frss.php%3Fid%3D10001_05222025.xml'.\n"
     ]
    }
   ],
   "source": [
    "run_supervisor_agent(\"05222025\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
